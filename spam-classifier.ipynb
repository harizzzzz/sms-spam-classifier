{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: Text SPAM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd #handles the csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression # import logisticregression model\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix #handles models output metric report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1  ... Unnamed: 4\n",
       "0   ham  ...        NaN\n",
       "1   ham  ...        NaN\n",
       "2  spam  ...        NaN\n",
       "3   ham  ...        NaN\n",
       "4   ham  ...        NaN\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset-use pandas library\n",
    "df=pd.read_csv('sms_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from the head before, it can be seen there is 3 unneeded columns\n",
    "# lets remove it\n",
    "df=df[['v1','v2']]\n",
    "df=df.rename(columns={'v1':'label','v2':'text'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so now, lets observe the class label\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4825\n",
       "1     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it shows that there is only two class labels\n",
    "# ham or spam\n",
    "# to train a model, we need to convert the value into \n",
    "# numeric values 0 or 1\n",
    "df['label']=df['label'].map({'ham':0,'spam':1})\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then in order to train model, let's split data\n",
    "# into 8:2 ratio, 80% training and 20% testing\n",
    "x_train,x_test, y_train, y_test=train_test_split(\n",
    "    df['text'],df['label'], # y should be class label- i think?-yes, confirmed\n",
    "    random_state=42,test_size=0.2, # random_state will control the data shuffling (0~42)\n",
    "    stratify=df['label'] # test size is 0.2-20%, stratify- do stratified sampling- the column automatically become class label\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the countvectorizer and tfidfvectorizer\n",
    "count_vectorizer=CountVectorizer(stop_words='english') # use prebuilt english stop words dictionary\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english',max_df=0.7) # set condition that words can only appear in maximum 70% of documents to be included in vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to consider:\n",
    "- CountVectorizer vs Tf-Idf Vectorizer\n",
    "---------------------------------------\n",
    "1-Count vectorizer only generate vectors where each  element represent the raw count of a word in the documents.\n",
    "\n",
    "2- TfIdf vectorizer  calculates TF_IDF scores for each word, considering how often it appears in a document (term-freq) and how rare it is across all documents (idf)\n",
    "\n",
    "3- Count good for simple count task -basic analysis\n",
    "\n",
    "4- TFIdf considered better for text classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text data into Tf-idf-weighted document-term matrix\n",
    "x_train_count=count_vectorizer.fit_transform(x_train)\n",
    "x_test_count=count_vectorizer.transform(x_test)\n",
    "x_train_tfidf=tfidf_vectorizer.fit_transform(x_train)\n",
    "x_test_tfidf=tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why in transforming train and test set using different operators?\n",
    "\n",
    "-fit_transform (let the model learn new words and transform the text into vectors)\n",
    "-transform (just convert text into vectors)\n",
    "\n",
    "so, fit transform is suitable for train set, while transform is suitable for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Accuracy:  0.9766816143497757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       966\n",
      "           1       1.00      0.83      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.91      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Confusion Matrix: \n",
      " [[966   0]\n",
      " [ 26 123]]\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression model using CountVectorizer\n",
    "logres_countv=LogisticRegression()\n",
    "logres_countv.fit(x_train_count,y_train)\n",
    "\n",
    "# test the train model using test set\n",
    "y_pred_countv = logres_countv.predict(x_test_count)\n",
    "\n",
    "# utilize accuracy score to show the model accuracy\n",
    "print(\"CountVectorizer Accuracy: \", accuracy_score(y_test,y_pred_countv))\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_test,y_pred_countv))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test,y_pred_countv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorizer Accuracy:  0.967713004484305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       966\n",
      "           1       1.00      0.76      0.86       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.92      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Confusion Matrix: \n",
      "[[966   0]\n",
      " [ 36 113]]\n"
     ]
    }
   ],
   "source": [
    "# train the logistic regression model using TFIdf vectorizer\n",
    "logres_tfidf=LogisticRegression()\n",
    "logres_tfidf.fit(x_train_tfidf,y_train)\n",
    "\n",
    "#test the trained model\n",
    "y_pred_tfidf=logres_tfidf.predict(x_test_tfidf)\n",
    "\n",
    "# print the accuracy report\n",
    "print(\"TF-IDF Vectorizer Accuracy: \", accuracy_score(y_test,y_pred_tfidf))\n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test,y_pred_tfidf))\n",
    "\n",
    "#print confusion matrix\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test,y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models trained on vectors from CountVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Logistic Regression': LogisticRegression(), 'Naive Bayes': MultinomialNB(), 'Random Forest': RandomForestClassifier(random_state=42), 'SVM': SVC(random_state=42)}\n",
      "Results with CountVectorizer converter: \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression: \n",
      "Accuracy: 0.9767\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       966\n",
      "           1       1.00      0.83      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.91      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Confusion Matrix: \n",
      "[[966   0]\n",
      " [ 26 123]]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes: \n",
      "Accuracy: 0.9839\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       966\n",
      "           1       0.96      0.92      0.94       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.96      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Confusion Matrix: \n",
      "[[960   6]\n",
      " [ 12 137]]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest: \n",
      "Accuracy: 0.9713\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       966\n",
      "           1       1.00      0.79      0.88       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.89      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Confusion Matrix: \n",
      "[[966   0]\n",
      " [ 32 117]]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM: \n",
      "Accuracy: 0.9758\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       966\n",
      "           1       1.00      0.82      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.91      0.94      1115\n",
      "weighted avg       0.98      0.98      0.97      1115\n",
      "\n",
      "Confusion Matrix: \n",
      "[[966   0]\n",
      " [ 27 122]]\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# initiate a set of models - logres, naivebayes, svm, random forest\n",
    "models={'Logistic Regression': logres_countv,\n",
    "        'Naive Bayes':MultinomialNB(),\n",
    "        'Random Forest': RandomForestClassifier(random_state=42),\n",
    "        'SVM':SVC(random_state=42)}\n",
    "\n",
    "print(models)\n",
    "\n",
    "print(\"Results with CountVectorizer converter: \")\n",
    "print(\"-\"*70)\n",
    "for name, model in models.items():\n",
    "    #train each model -fit(x train set(count or tfidf vector), y train set)\n",
    "    model.fit(x_train_count,y_train)\n",
    "    #produce prediction- predict(x test set (count or tfidf vectir))\n",
    "    y_pred=model.predict(x_test_count)\n",
    "    # print the result for each model\n",
    "    print(f\"\\n{name}: \")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test,y_pred):.4f}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"Confusion Matrix: \")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models trained on vectors using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result with TF-IDF Vectorizer: \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression: \n",
      "Accuracy: 0.9677\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       966\n",
      "           1       1.00      0.76      0.86       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.92      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Confusion Matrix: \n",
      "[[966   0]\n",
      " [ 36 113]]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes: \n",
      "Accuracy: 0.9686\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       966\n",
      "           1       1.00      0.77      0.87       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.92      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Confusion Matrix: \n",
      "[[966   0]\n",
      " [ 35 114]]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest: \n",
      "Accuracy: 0.9731\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       966\n",
      "           1       1.00      0.80      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.90      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Confusion Matrix: \n",
      "[[966   0]\n",
      " [ 30 119]]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM: \n",
      "Accuracy: 0.9785\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       966\n",
      "           1       0.99      0.85      0.91       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Confusion Matrix: \n",
      "[[965   1]\n",
      " [ 23 126]]\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Result with TF-IDF Vectorizer: \")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for name,model in models.items():\n",
    "    model.fit(x_train_tfidf,y_train)\n",
    "    y_pred=model.predict(x_test_tfidf)\n",
    "    # print the result for each model\n",
    "    print(f\"\\n{name}: \")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test,y_pred):.4f}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"Confusion Matrix: \")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\"-\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
